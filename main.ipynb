{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from glob import glob \n",
    "from tqdm import tqdm \n",
    "import pickle \n",
    "import time \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score,roc_curve,auc\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn  \n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset,DataLoader \n",
    "from torch import optim \n",
    "\n",
    "from src.model import Discriminator,Generator,weights_init\n",
    "from src.Dataset import SwatDataset\n",
    "from src.Options import OPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/pre_data.pickle','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "opt = OPT()\n",
    "\n",
    "train_set = SwatDataset(data,'train')\n",
    "test_set = SwatDataset(data,'test')\n",
    "train_loader = DataLoader(train_set,batch_size=opt.batchsize,shuffle=True)\n",
    "test_loader = DataLoader(test_set,batch_size=opt.batchsize,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_netd(batch_x):\n",
    "    D.zero_grad()\n",
    "    # Train with real \n",
    "    out_d_real, feat_real = D(batch_x)\n",
    "\n",
    "    # Train with fake \n",
    "    fake, latent_i = G(batch_x)\n",
    "    out_d_fake, feat_fake = D(fake)\n",
    "\n",
    "    err_d_real =  bce_criterion(\n",
    "                                out_d_real.type(torch.float64), \n",
    "                                torch.full((opt.batchsize,),  real_label).type(torch.float64).to(device)\n",
    "                                )\n",
    "    err_d_fake =  bce_criterion(\n",
    "                                out_d_fake.type(torch.float64), \n",
    "                                torch.full((opt.batchsize,),  fake_label).type(torch.float64).to(device)\n",
    "                                )\n",
    "\n",
    "    err_d = err_d_real + err_d_fake\n",
    "    err_d.backward()\n",
    "    optimizerD.step()\n",
    "    return err_d_real,err_d_fake\n",
    "\n",
    "def update_netg(batch_x):\n",
    "    G.zero_grad()\n",
    "    fake,latent_i = G(batch_x)\n",
    "    out_g,feat_fake = D(fake)\n",
    "    _,feat_real = D(batch_x)\n",
    "\n",
    "    err_g_adv = mse_criterion(feat_fake,feat_real)\n",
    "    err_g_rec = mse_criterion(fake,batch_x)\n",
    "\n",
    "    err_g = err_g_rec + err_g_adv * opt.w_adv\n",
    "    err_g.backward()\n",
    "    optimizerG.step()\n",
    "    return err_g_rec,err_g_adv\n",
    "    \n",
    "def reinitialize_netd():\n",
    "        \"\"\" Initialize the weights of netD\n",
    "        \"\"\"\n",
    "        D.apply(weights_init)\n",
    "        print('Reloading d net')       \n",
    "        \n",
    "def optimize(batch_x):\n",
    "    err_d_real,err_d_fake = update_netd(batch_x)\n",
    "    err_g_rec,err_g_adv = update_netg(batch_x)\n",
    "    \n",
    "    err_d = err_d_real.item() + err_d_fake.item() \n",
    "    err_g = err_g_rec.item() + err_g_adv.item()\n",
    "    \n",
    "    errors = {'err_d':err_d,\n",
    "                    'err_g': err_g,\n",
    "                    'err_d_real': err_d_real.item(),\n",
    "                    'err_d_fake': err_d_fake.item(),\n",
    "                    'err_g_adv': err_g_adv.item(),\n",
    "                    'err_g_rec': err_g_rec.item(),\n",
    "                  }\n",
    "    \n",
    "    if err_d < 5e-6:\n",
    "        reinitialize_netd()\n",
    "    return  errors           \n",
    "\n",
    "def train_epoch(dataloader):\n",
    "    global total_steps\n",
    "    G.train()\n",
    "    D.train()\n",
    "    epoch_iter = 0 \n",
    "    for batch_x,batch_y in dataloader:\n",
    "        total_steps += opt.batchsize \n",
    "        epoch_iter +=1 \n",
    "        \n",
    "        batch_x,batch_y = batch_x.type(torch.float32).to(device),batch_y.type(torch.float32).to(device)\n",
    "        \n",
    "        errors = optimize(batch_x)\n",
    "        \n",
    "        if (epoch_iter % 1000) == 0:\n",
    "            print(f\"\\n Epoch : {cur_epoch} | [{epoch_iter}/{dataloader.__len__()}]\" )\n",
    "            print(f\"\\n D_loss(R/F) : {errors['err_d_real']:.4f}/{errors['err_d_fake']:.4f}, G_loss : {errors['err_g']:.4f}\")\n",
    "\n",
    "    \n",
    "##predict \n",
    "def predict(dataloader,scale=True):\n",
    "    G.eval()\n",
    "    D.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        an_scores = torch.zeros(size=(len(dataloader.dataset),), dtype=torch.float32, device= device)\n",
    "        gt_labels = torch.zeros(size=(len(dataloader.dataset),), dtype=torch.long,    device= device)\n",
    "        dis_feat = torch.zeros(size=(len(dataloader.dataset),  opt.ndf*16*10), dtype=torch.float32,device= device)\n",
    "\n",
    "\n",
    "        for i, (batch_x,batch_y) in enumerate(dataloader):\n",
    "            batch_x,batch_y = batch_x.type(torch.float32).to(device),batch_y.type(torch.float32).to(device)\n",
    "            fake, latent_i =  G(batch_x)\n",
    "            # error = torch.mean(torch.pow((d_feat.view( input.shape[0],-1)-d_gen_feat.view( input.shape[0],-1)), 2), dim=1)\n",
    "            #\n",
    "            error = torch.mean(\n",
    "                torch.pow(( batch_x.view( batch_x.shape[0], -1) -  fake.view( fake.shape[0], -1)), 2),\n",
    "                dim=1) # reconstruction loss \n",
    "\n",
    "\n",
    "            gt_labels[i* opt.batchsize : i* opt.batchsize+error.size(0)] =  torch.max(batch_y,dim=1).values.reshape(error.size(0)) #y \n",
    "            an_scores[i* opt.batchsize : i* opt.batchsize+error.size(0)] = error.reshape(error.size(0)) #y_pred\n",
    "            \n",
    "        # Scale error vector between [0, 1]\n",
    "        if scale:\n",
    "             an_scores = (an_scores - torch.min(an_scores)) / (torch.max(an_scores) - torch.min(an_scores))\n",
    "\n",
    "        y_= gt_labels.detach().cpu().numpy()\n",
    "        y_pred = an_scores.detach().cpu().numpy()\n",
    "\n",
    "        return y_,y_pred\n",
    "#def evaluate(train_loader,test_loader):\n",
    "def evaluate(test_loader):\n",
    "    test_y,test_y_pred = predict(test_loader)\n",
    "    train_y,train_y_pred = predict(train_loader)\n",
    "    #thres = np.percentile(np.concatenate([test_y_pred,train_y_pred]),1)\n",
    "    thres = 0.02 \n",
    "    \n",
    "    y_pred_thres = pd.Series(test_y_pred).apply(lambda x : 1 if x > thres else 0).values\n",
    "    #auc = accuracy_score(y,y_pred)\n",
    "    precision, recall, f_score, support = precision_recall_fscore_support(test_y, y_pred_thres,\n",
    "                                                                                average='binary')\n",
    "    fpr,tpr,thr = roc_curve(test_y,test_y_pred)\n",
    "    auroc = auc(fpr,tpr)\n",
    "    \n",
    "    return precision, recall, f_score, auroc    \n",
    "\n",
    "def validate(dataloader,thres):\n",
    "    y_,y_pred = predict(dataloader)\n",
    "    precision, recall, f_score, auroc = evaluate(y_,y_pred,thres)\n",
    "    return precision, recall, f_score, auroc \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch : 1 | [1000/2327]\n",
      "\n",
      " D_loss(R/F) : 0.0075/0.0638, G_loss : 0.3229\n",
      "\n",
      " Epoch : 1 | [2000/2327]\n",
      "\n",
      " D_loss(R/F) : 0.0254/0.0739, G_loss : 0.2329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:59<1:38:21, 59.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----------------------------------------------------------------\n",
      "\n",
      " Precision : 0.259 | Recall : 0.970 | F1-score : 0.408 | AUROC : 0.682\n",
      "\n",
      " ----------------------------------------------------------------\n",
      "\n",
      " Epoch : 2 | [1000/2327]\n",
      "\n",
      " D_loss(R/F) : 0.0083/0.0389, G_loss : 0.2328\n",
      "\n",
      " Epoch : 2 | [2000/2327]\n",
      "\n",
      " D_loss(R/F) : 0.0853/0.0434, G_loss : 0.1717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [01:59<1:37:28, 59.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----------------------------------------------------------------\n",
      "\n",
      " Precision : 0.285 | Recall : 0.929 | F1-score : 0.437 | AUROC : 0.687\n",
      "\n",
      " ----------------------------------------------------------------\n",
      "\n",
      " Epoch : 3 | [1000/2327]\n",
      "\n",
      " D_loss(R/F) : 0.0031/0.0468, G_loss : 0.1932\n",
      "\n",
      " Epoch : 3 | [2000/2327]\n",
      "\n",
      " D_loss(R/F) : 0.4446/0.0046, G_loss : 0.1617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [02:59<1:36:36, 59.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----------------------------------------------------------------\n",
      "\n",
      " Precision : 0.278 | Recall : 0.940 | F1-score : 0.429 | AUROC : 0.689\n",
      "\n",
      " ----------------------------------------------------------------\n",
      "\n",
      " Epoch : 4 | [1000/2327]\n",
      "\n",
      " D_loss(R/F) : 0.0021/0.1145, G_loss : 0.1727\n",
      "\n",
      " Epoch : 4 | [2000/2327]\n",
      "\n",
      " D_loss(R/F) : 0.0096/0.1177, G_loss : 0.1634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [03:59<1:35:44, 59.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----------------------------------------------------------------\n",
      "\n",
      " Precision : 0.280 | Recall : 0.933 | F1-score : 0.430 | AUROC : 0.688\n",
      "\n",
      " ----------------------------------------------------------------\n",
      "\n",
      " Epoch : 5 | [1000/2327]\n",
      "\n",
      " D_loss(R/F) : 0.0456/0.0114, G_loss : 0.1902\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "G = Generator(opt).to(device)\n",
    "G.apply(weights_init)\n",
    "\n",
    "D = Discriminator(opt).to(device)\n",
    "D.apply(weights_init)\n",
    "\n",
    "bce_criterion = nn.BCELoss()\n",
    "mse_criterion = nn.MSELoss()\n",
    "\n",
    "optimizerD = optim.Adam(D.parameters(),lr=opt.lr,betas=(opt.beta1,0.999))\n",
    "optimizerG = optim.Adam(G.parameters(),lr=opt.lr,betas=(opt.beta1,0.999))\n",
    "\n",
    "total_steps = 0 \n",
    "cur_epoch = 0 \n",
    "\n",
    "real_label = 1 \n",
    "fake_label = 0 \n",
    "\n",
    "train_hist = {} \n",
    "train_hist['D_loss'] = []\n",
    "train_hist['G_loss'] = []\n",
    "best_f = 0 \n",
    "best_f_epoch = 0 \n",
    "\n",
    "for epoch in tqdm(range(opt.niter)):\n",
    "    try:\n",
    "        cur_epoch +=1 \n",
    "        train_epoch(train_loader)\n",
    "    except:\n",
    "        pass                 \n",
    "    precision, recall, f_score, auroc = evaluate(test_loader)\n",
    "    print('\\n ----------------------------------------------------------------')\n",
    "    print(f'\\n Precision : {precision:.3f} | Recall : {recall:.3f} | F1-score : {f_score:.3f} | AUROC : {auroc:.3f}')\n",
    "    print('\\n ----------------------------------------------------------------')\n",
    "    \n",
    "    \n",
    "    if f_score > best_f:\n",
    "        best_f = f_score\n",
    "        best_f_epoch=cur_epoch\n",
    "        \n",
    "        torch.save(G,'./save_models/G.pt')\n",
    "        torch.save(D,'./save_models/D.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
